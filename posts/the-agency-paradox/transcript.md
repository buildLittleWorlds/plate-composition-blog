URL: https://youtu.be/M2yiAFLPEZg?si=vhmliD7WP9cxQbZI
==============================
Channel Title: Truckee Meadows Community College
Video Title: Resisting AI for Writing Assignments
Publish Date: November 14, 2025
==============================

TRANSCRIPT:

Good afternoon. My name is Kylie Row. I'm the executive director of research, marketing, and public affairs. I'm happy to be your host for this session. We're so glad you're here. Please feel free to turn on your camera if you're comfortable. We'd also love you to introduce yourself. Please take the time right now to just put your name and your institution in the chat. We'd love to see who's joining us in this virtual space. It's my pleasure to introduce you to Dr. Rob Lively from TMCC. Rob is a professor of English at Truckucky Meadows Community College. He holds a PhD in English, writing, rhetorics, <2>
and literacies from Arizona State University. One of the goals of this summit is to have honest conversations about both the opportunities and the limits of AI. We've heard about some exciting applications, but it's equally important to hear from those who are asking tough questions about when AI use might cross the line in writing assignments. In other words, not every discipline or every classroom benefits from AI in the same way. Today's session will challenge us to think critically about where AI doesn't belong and why those boundaries matter. And with that, I'll hand things over to Dr. Lively <3>
as he presents Resisting AI for writing assignments. Thanks a lot. &gt;&gt; Thanks, Kylie. Um, I I know like a lot of people at the summit are kind of pro AI, but I'm totally in the other camp. I do not like AI. Um, I make no bones about it. Um, and I think a lot of the the hype right now is just that's all it is. It's hype. and um really looking a lot of educational materials and what's coming out that people using AI is hugely problematic. And so I want to I kind of want to throw some other issues in here um about uh about AI use in the classroom especially centered around writing assignments <4>
because people have a tendency to want to use that for lots of things. So um let me see if I can screen share this real quick. Okay, so yeah, resisting AI for writing assignments. I think it's really important for us to really think about why we have people write and what some of the actual issues are when people use AI instead of actually their own brain power to to write. Um, and one of the things I see a lot of people saying is like, oh, we're going to use AI ethically. But it's really impossible to use AI ethically if you really think about what ethics is. And it's this idea of moral guidelines <5>
and principles that govern how we produce our work. And so if you emphasize honesty, accuracy, and respect for intellectual property, then um you can't really use AI in any meaningful way. Um this is a little definition of um writing ethics. Um but um it's it's really problematic. The first one is it's environmentally destructive. Um AI uses water resources at an alarming rate. Um estimates suggest that a water consumption is just not sustainable. And another bad thing is that a lot of AI companies that are using these big data centers, they're targeting small and rural communities and they're <6>
really devastating a lot of their um you know, a lot of their uh uh water infrastructure. Um you know, they're they're pulling so much water out of the ground that uh wells are going dry and um you know, small farmers uh places, you know, they're they're having their water table destroyed. And so it's really hurting a lot of like uh not only in the US which we would normally think of um where we have like uh you know small towns in like the Midwest uh there's a huge story in Georgia right now about uh they built an AI data center and basically devastated the entire community because they have no <7>
water now. Um it hurts small farmers, people like that. But if we want to think a little more globally about AI usage, um a lot of AI data centers now are being built in um like third world countries. So the people there even have a less margin for error with water resources. And so places like in in Mexico and like small villages, uh places in Africa, um the water table is just being devastated by all the water sucking out to cool all of the uh all the servers that are there. And so like people are actually dying because of AI usage. Um and it you know it really hurts these things. And so like <8>
when we go and turn on the tap water or take a shower, we we don't really think about it. But actually this is this is devastating to entire communities and entire areas um just for this thirst for water. Um and it's a it's a huge um it's a huge problem because uh you know you'll see like lots of articles about just water usage. Um there's a couple here and then like there's a bunch across here just looking at data water center usage um and and people have said um that this data water center usage um uh you know they have these now these things called closed systems u but if you really read into <9>
that it's just a marketing ploy because what happens is they go to these communities and they have to take water from wells which has a lot of mineral content and then they pump it into this data center and then they close it off but then they their the um servers are running so hot when they're water cooling. Uh it bakes in a lot of scale from the mineral content. So then they have to dump all the water out, flush the system and pump new water in. So it really becomes problematic to use this kind of uh you know this kind of technology especially with the with the um you know the small towns and <10>
and small villages and stuff being affected. So that's that's a problem you know just just ethically. Um, and then another problem, you know, thinking about it is AI is created by stealing, uh, from authors and artists, um, you know, to get these large U models, they they scrape. And so, a lot of times they're scraping and they're not actually doing it legally. They're just stealing people's works. Anything online or something that's posted or it's on a a site or something, even things we post on like Canvas, everything can be scraped. And so, this is problematic because it deals with intellectual <11>
property. Um there's, you know, tons of lawsuits right now um against uh AI companies um for stealing writer works. Um and it's not a it's not a fluke of AI. It's actually a model for AI to steal. Um OpenAI um here you have Altman here. Uh this is an article from Futurism, but he says it's over if AI can't steal your copyrighted work. So I mean they have a business model that's built on theft. Okay, which I find hugely problematic as as a writer myself. And I don't want, you know, my students using work that's stolen. You know, I don't want people stealing things in general. And I think intellectual <12>
property is just as good as real property. And you can't go around just taking other people's stuff. So, it's it's, you know, really problematic for this kind of thing. Um, and then the last thing, AI. I know people disagree with this, but AI is plagiarism. um they're taking they're literally stealing because they're scraping stuff. They're stealing other people's work and then they're passing it off as the students are as their own. Um and even if they even if they cite it, it's stolen work. So it's plagiarism on on some level. Um so that creates a a huge problem. Um and then a lot of times students <13>
are plagiarizing with this uh AI tech and they're it's not even citing it. they're just turning it in which you know they're presenting you know a a language generated model as their own work. So this creates another issue. Um you know uh plagiarism is this appropriation of another person's ideas process as a result. I mean that's the definition of an AI scrape. Um so it it creates lots of problems for me ethically just in the writing classroom. Um so I have a hard time you know backing it up in any way, shape or form. Um if we get into the writing aspect um I hear all kinds of things about different <14>
aspects of the writing process. So, um I I hear stuff like why not use AI for prewriting? Um and this is in in comp studies going back as early as 1963. Uh this guy Roman WKEI uh showed that prewriting practice is the best way to develop organization and idea development student writing. Um they term it discovery in in their essay. But the idea of invention is one of the cannon of rhetoric and it goes back to ancient Greece. Um if you read like Aristotle or probably the most famous work on invention is uh Cicero's de Invention. Um but you know it's this idea of how do you put together a paper? <15>
How do you think about it? And prewriting is really good for students because it creates an architecture in their mind of the problem they want to engage with, what they're researching, how they want to approach it, uh how can they, you know, affect the audience. These are things that, you know, prewriting really helps with when students encounter it. And so we need to actually cultivate that, not diffuse it. Um, Peter Elbow, um, he's a real well-known composition scholar. Uh, he argues that prewriting is the first chance students get to engage with the material. And so it's one of the most important <16>
steps in writing, not a castoff step. Um, so if we use AI, we're denying students this important step in thinking and engaging with material. Um, because then it's not their paper. AI has generated some kind of outline or form or something and then they sort of fill in the blanks. And we don't want them thinking about writing as some kind of, you know, computerenerated Mad Lib. We want them to actually be thinking about how they can make rhetorical choices in their writing. And it starts with prewriting. Okay. Um, and then if you think about it, you know, the purposes of writing when we write, <17>
when we want students to write in our classes, um, whack theory suggests a couple of instances, right? um they either uh you know write to learn and learn to write and these are things that are really important um not just for a classroom but for their development into their fields. So, you know, students learn about topics from their writings, right? They they think about it. You have them read stuff, you engage with them, they think about it, they write about it, and they're, you know, engaged with it. And so, but not only that, we have um we have the ability, you know, and we do this, we professionalize <18>
them into their fields. So, not only do we have them engage with writing to learn something, but we're slowly professionalizing them into our fields. So if you're teaching on anthropology or uh political science or math or biology, whatever you're doing, you're teaching them to think and write like that discipline, you know. So you think about like, you know, how does a biology professor write or how does a you know, a person going into public affairs write or something like that. Um these are these are thinking and engaging topics, you know, and and they learn to write like that. They engage in <19>
that discourse community with their major. And so um James G who's another comp scholar he's a linguist does a lot of linguistic stuff um he has a famous essay called literary discourse and linguistics and he argues that this professionalization is creating an identity kit for the student right it's something that they will take with them when they leave you know TMCC you know a university whatever and it's professionalized them into that field so no longer are they just writing in general they're writing like an anthropologist or writing like a biologist and this is something that you know if <20>
They if they learn if they do their writing through AI, they learn neither of these things, they don't engage with the material and they don't learn that professional discourse that makes them an anthropologist or what it means to be a biologist. They don't know that discourse. They don't know how it they think. They don't know how to write it because they've never had to do it. And so they go out and with supposedly, you know, they're going out and getting professionalized into these fields. um using AI in their writing, they actually don't learn the discourse that will help them professionally <21>
when they leave a university or you know whatever program they're in. So this is this is to me is very problematic and it's at the core of uh writing across the curriculum pedigogy. So this this creates all kinds of problems as well. Um I know chat GPT and other people are building these search engines using AI but AI is not a search engine. Um, a real search engine will return only real sources based on keywords. Um, AI will make up source material to fulfill the prompt. It was never designed to be a search engine. And this is this is problematic. Um, we an English professor uh, Lindseay Wilson, <22>
he tried using chat GPT to generate uh, a source material using it as a search engine and it it delivered six fake sources to him. So then he said, "No, no, no. I need real sources." and said, "Oh, okay. I misunderstood." And generated him six more fake things. And he did it another time saying, "No, I want real sources that exist, you know, in the real world." And it created six more fake ones. So, if you start using AI as a search engine, it's going to create a lot of fake materials. And this is problematic on a levels. I'll talk about it in a little bit, but this AI as a search engine is a real <23>
problem. Um, bad quotes and data get leeched into academic discourse doing this. Um, fake quotes from fake sources are appearing in academic journals now from people who used chat GPT. Um, and I ran across this personally. I was writing an essay on um on Star Trek um writing uh their their 50-y year anniversary Star Trek uh edited collection. I was writing an essay on uh humanistic education. And I found two academic journals that had a source that they both cited the same source and I um I was going to use it. I didn't have TMCC didn't have the uh original, but I saw it in two peer-reviewed journals. <24>
And so I said, "Oh, this is a great quote. I can use it." And I just did an attribute never existed. So, um, you know, you see this stuff leeching into academic journals now. Um, they've had it problems in biology with this. And, um, there's a bunch of stuff in in legal, and we'll get to that in a second. Um, to get better results, you're doing search engine, you can put minus AI after you search the term. So, if you did like new vaccine data, minus AI, um, you know, it'll it'll turn out things that aren't AI generated. Um, or you can just use databases. Um, we have them at TMCC. All colleges have <25>
them and they're actually curated knowledge collections and these are things that are more reliable than getting like some fake sources. Uh, we found that students using AI um have a lot of fake sources in their works. Um, they're creating all kinds of weird um, you know, documentation issues which is, you know, problematic. Um, and so students need to be told how to avoid AI problems and searches because AI at this point is totally unreliable. um it creates all kinds of all kinds of issues for us. Um AI also limits critical thinking. I don't know if you saw the um Whoops. Ah um I don't know if <26>
you saw the uh the study from MIT um but they did um uh they looked at students writing and engaging in activities using um just their brain an LLM assist or a LLM completely using AI. And what they found is that there was this cognitive debt and cognitive offloading when people were using LLMs. They stopped thinking. People using full-on AI to do their work uh were registering no brain activity at all. And this is really really problematic. And so um if you look at it, um the the big conclusion here was over the four months of the study, LLM users consistently underperformed at neural, linguistic, <27>
and behavioral levels. Uh these results raise concerns about long-term educational implications of LLM reliance and underscore the need for deeper inquiry um into AI's role in learning. So this is this is hugely problematic. Um and this was done at MIT not some fly by night organization. Um and they found that you know AI actually was you know created cognitive debt. Students actually got dumber from using AI. So this creates you know all kinds of issues if we're thinking about education. Um, another thing, um, AI takes away student agency. Um, students have shown an overreiance on AI and decision- <28>
making. Um, and this is going beyond some of the other stuff like AI as like therapists and stuff like that. I mean, that's a whole other issue. Uh, but this is just decision- making for their writing. Um, you know, I if instructors tell them, oh, listen to AI or or, you know, use AI, students automatically think they're wrong because the computer's telling them to make changes. So, they're not considering any rhetorical choices that they want to make. Uh, they just assume that they're wrong and even if the AI has elucidated something or if it's technically incorrect, um, they'll just change it <29>
because the computer told them to. Um, that also is a huge problem. So developing some thoughtful reflective writers who make choices is the purpose of creating writing choices in the first place, right? You know, you want people to make their own, you know, rhetorical choices to influence or to inform um how they want to do it. Um and struggling, you know, students are struggling. That's actually really good. They're thinking about it. How do they do it? What do they learn from it? You know, um you you don't have to be successful every single time. sometimes you know you you're really struggling <30>
with something but you actually learn a lot by that you know that process um and if you want to think about uh Votssky's zone of proximal development um Votssky educational theorist um you know uh he said working through the problem is beneficial but AI if you just throw it out to this computer it takes that learning opportunity away and creates something that may or not actually be valid so that's that's problematic for student learning as well so students really need to learn to make informed choices in their writing. And using AI to change the tone or clean up a draft is really detrimental to <31>
a writer's development because that cleaning up and changing tone is something that are rhetorical choices that students should be taught to make. They should know how to do it, you know, rather than just, you know, farming out. They they don't understand. They never learn it. Um it's taking away human agency from the students. Um AI also hurts diversity. I know people say like, "Oh, it's great. and it helps people. Um, I was at a conference and this person was talking about how great AI was for minority students because they could write an AI paper and turn it in and get a better grade. And this <32>
one lady who is African-American stood up and said, "What I'm hearing is you think, you know, minorities are too stupid to learn." Um, and so she was very upset with the the presentation. Um, she may have used some cuss words. Um, so, uh, you know, it it it hurts diversity in a lot of ways. one because um not all minorities are a monumental block of people. You know, there's there's differences and AI has a tendency to homogenize things and so it takes away voice from anybody, you know, with a diverse standpoint. Um in the book naming what we know, which is a huge composition um textbook uh talks <33>
about theory and construction and where the discipline is in writing. Uh there are several chapters devoted to the idea of writing constructing identity. And so AI cannot help students with this because AI can't be authentic in diversity. It's a generalizer. It amalgamates and it has no sense of what it means to be a person of color or a person who is trans or anything like that. It can just scrape and create this weird amalgamation of stuff. You know, you could never you could never have AI write an authentic uh you know essay about what it means to be a child growing up in Gaza right now. I mean, <34>
you could get a paper generated. it would be fake. Um, but you'd lose that lose that diversity of opinion. Um, USC has a statement I thought was interesting, but it says that a generative AI models aggregate information from large data sets that contain biases. This can generate content that may perpetuate negative stereotypes and tropes or fail to adequately represent genuine voices and experiences of students of color and other diverse population segments. These individuals may encounter AI generated materials that minimize their perspectives and experiences or worse AI source information could <35>
be historically inaccurate and rely on past racist beliefs and views. So I mean just as a you know something that was done recently that was so stupid but um Musk recently retoled his AI and then it declared itself Mecca Hitler and spouted racist views. I don't know if you guys saw that. Um and then had to take it down. Um, and so AI scrapes the internet and students accessing this um, info get many racist, biased, and hatefilled views. Um, and it doesn't really promote diversity. It actually takes away from diversity because it takes away the unique perspectives of people of color. Um, or you <36>
know, uh, you know, minority groups and, you know, just it it really really ends up being a negative, not a positive. Um, if all your if your main point is like, oh, students can get uh, you know, they can use AI and get like a B minus paper. If that's your that's your form of success, then great. But here, if they're really talking about an actual point of view or diversity or anything, um, AI really fails in this quite quite horribly, actually. Um, there's a bunch more things you can point to. Um, a lot of, uh, you know, online gaming communities have tried to use AI chat bots and, you know, <37>
my son was on a, um, a site and they they opened up a chatbot for like a moderator and within two days had to shut it down because it basically become a full-on Nazi using all kinds of horribly racist uh, terms and stuff for gamers. So, they had to shut it down. um but it scrapes and so it just takes whatever's out there and there's a lot of negative stuff on the internet. Um and then AI is really really bad at research. If you haven't had this um problem with students um I'm actually kind of surprised if you haven't. Um AI AI um AI hallucinations are a huge problem. Uh they make up all kinds of <38>
facts, data, and people. Uh and this hurts student performance that does not enhance it. Uh, we want our students to find real information. And I don't know if you guys know or saw this today, but the BBC put out an article today where it tried using AI to summarize news articles and it found it got things horribly, horribly wrong. About half the time, um, the summaries of actual stories were wrong. So, it couldn't even summarize a news article. Um, and so the BBC and the European Broadcasting Union, I think it was, um, they did this big study and they found out that, you know, this was terrible <39>
for, uh, you know, you know, trying to do any type of research. It would give you those little summaries, uh, much like a little abstract of the article, but they were wrong most of the time. Um, and there, um, this is a huge problem when we get into, uh, people doing research in law. And there have been a ton of stories on this and I wanted to put some in here to show you guys some of the uh the horrible uh legal stuff in here. Um no lawyer has been disbarred yet, but several have been censured and and some have been fined quite a bit. Um but lawyers have been trying to farm out AI to uh write <40>
their legal briefs and legal stuff and it's uh it's faking uh case law and so um they go into court and they're supposedly citing this for precedent. you right one of the foundations of our legal system well allegedly these days but precedent um of the uh you know the legal system over the years and AI is just faking case law um and so uh lawyers who have been caught have been censured um the second one down here there was an Australian murder case where uh this guy was on trial for murder and his lawyer was using AI and it made all kinds of fake stuff so do you trust AI to save your life if you're <41>
in a murder case or you going to spend the rest of your life behind bars because you trusted this thing that we know hallucinates. Um they got um all kinds of problems here. I gave in this right here there are several um articles here that talk about uh different types of uh of problems of AI hallucinations in courtrooms. And it's it's a huge problem. I mean if you go to court and your lawyer is using AI that's hallucinating case law, it could affect your life. It could affect you financially. It could affect your freedom. um it's hugely problematic and these are these are people who should be <42>
writing their own stuff you know and if you're trying to professionalize people into into that discipline we s we have students leave TMCC I know I've had some who've gone on to become lawyers and I would be terrified if they were actually using you know AI to make legal briefs for me if I was ever on trial so this this creates a huge huge problem and um another one is uh if we Think about why we revise. I know um some people are going like, "Oh, students can draft stuff and use AI to help them revise." That also creates a problem for critical thinking and paper development. Um a revision of a <43>
paper is literally that. It's a revision. It's a reseeing of something. If students use AI to make these changes, they're losing out on that valuable writing skill. Um you're when you revise something, you metacognitively re-evaluate your ideas. You know, do they do they develop? Okay. Is there good organization here? Um, you know, what does the audience need to finish understanding what I'm trying to say? Um, they need to think about these things. AI is terrible at assessing audience. Um, they, you know, they they write stuff, but they can't really say like, okay, so what exactly is my is my audience? <44>
Um, and what do I need to do? Because part of the writing process is figuring out like how do I convey this information to a particular audience? And you know, the more you know about your audience, the better you can address that. And AI is terrible at doing that. Um you know uh and and Doug DS he was one of the creators of the writing about writing pedigogy. He says to create the best possible writing writers work iteratively composing a number of versions with time between each for reflection reader feedback andor collaborative development. Uh the revision implied is in the process that is significant <45>
development of text idea structure andor design is central to developing writing. You know, and this is something that we really need to think about is, you know, putting people through that process that that iteration process. Uh but but they're doing the work though, not something else they can farm out. They're actually doing it, you know, themselves. So this this creates, you know, problematic uh revision processes. Um and AI is really bad at revision. Um because AI scrapes and generates, it creates middle-of the road papers. So students sometimes have a really good idea and then they'll put <46>
it into chat GPT and the paper becomes less interesting because it creates it and makes a more common more generic draft. Um and then you know it that takes away all the excitement and everything. Um it takes away from the thinking students go through when making choices in their writing. Um you when you're revising you're making changes. Um, and if they just make changes the computer says, you know, then that's they're not really doing it. I mean, if AI brainstorms, write your paper, then revising it, what are the students learning? Absolutely nothing. Um, and one of the things that TMCC is all <47>
gung-ho about, which I cannot stand, is packback. Um, students do not need immediate feedback. They need to think about it. What does their paper need? How do they engage with it? What do they need to work through? So Packback actually takes away from critical thinking. It it it shoots them out something immediately that um then students will lose agency. They will just make the changes Packback says and they've lost out on that chance to do some real critical thinking about their work. There's no metacognition. There's no reflection there. Um also Packback is hugely problematic in my opinion because <48>
no one in Packback is actually a writing studies scholar. There's a lot of tech people in marketing if you look at their stuff. um their whole reason to be as a business model, not an educational tool. Um and if you've ever seen the Shark Tank where they started, they actually got their start on Shark Tank is a total train wreck. Um I put the link in here so you can watch it if you want to. Um they go in there and they present this and then u Mark Cuban offers to buy them out or buy a percentage of their work for uh $300,000 and then they argue saying like no we want 200,000 and Cuban's like all <49>
what I offered you 300,000 and then they're like oh so I mean that's the kind of people we have trusting our our writing our student writing. Um, also Mark Cuban, billionaire basketball owner, is not an education specialist. So these these people that we're trusting with student writing and student learning, they're not really education specialists. They're a lot of tech marketing people, um, tech people, not education people. And to me, that's a that's a huge thing because that's taking away from expertise. Um, you're buying into uh their marketing strategy, not actually education foundation. <50>
Um but some scholars are taking a stand. Um AI resistance is growing across all departments and campuses. Um there's a big movement now called analog teaching which is getting rid of all of technology basically. Um uh you know several people are using it where they they come to class you know um you you'll be writing you know in person you'll be doing stuff in class. There's no canvas use. they use a paper syllabus and there's you know because they're they want people to actually learn to think um and so uh there this is this is a big movement that's that's starting um students are also arguing <51>
units AI use on campus uh they want to develop skills um students are starting to write um you know articles in student papers um you know some online journal stuff um and they're taking a stand that they actually don't want to use AI um they actually want to develop skills because they realize that using AI is not really helping them with their uh with their learning. Um, and there's many books and articles being written against AI. Um, Scientific American has an article called Chat GPT isn't hallucinating, it's bullshitting. Um, Research Gate, there's another one. ChatGpt is Uh, this little spectrum, <52>
there's an article misinformation LLM And then, uh, even Cambridge University said, "Oops, we automated bullshit." So, I mean, there's people saying that Chad GPT is not a good educational source. It actually is hurting. So, it's not helping in in the sciences or or in, you know, writing. Um, they're they're finding this out. And books are being are starting to being written about how bad this is. Um, there's like AI snake oil. It's one of the big ones. Uh, the AI con. Uh, and this one is interesting. I haven't had a chance to read this one yet, but I read the some reviews on it and it looks really <53>
interesting to me. Um this is idea of moral codes. Um talking about some of the ethical problems of using AI and this guy talks about using tech to design alternatives to AI. Um and I think that can be a really good uh you know a really good uh starting point to really think about other options rather than just blindly following you know some some tech bros who you know want our money but not our our actually education. Um, and then big tech seldom delivers outlandish promises. And these are some things that have gone on the last few years. Um, remember gate schools? He was like a billionaire. <54>
You know, Bill Gates, they're going to re revolutionize school with the gate schools and they failed horribly. Um, MOOs, remember them? Um, yeah, those things. They were going to revolutionize education. They're gone. Uh, Musk once claimed we'll have a colony on Mars by 2024. No. Uh the metaverse, how's that going? Uh Google Glass, they keep trying to revise that, which never seems to work. Um how about Theronos is going to revolutionize, you know, was a big tech thing going to revolutionize medicine. And now Elizabeth Holmes, I think she's still in prison for scamming people. Um NFTTS, remember <55>
those nonf fungeible tokens, those things collapsed. And now we get another big promise, AI, right? They're throwing out all this stuff. Um, and AI is one of the instances where you have sort of the spaghetti approach. They say it'll do everything and everybody's trying to incorporate it in everything. And I think they're just trying to do it to see what sticks because they have no idea how it actually is going to work. Um, but right now it really hasn't affected things all that much. Um, as far as like helping. Um, it's been uh it's a losing proposition. Uh, 80 uh 80 to 95% of AI companies go <56>
out of business. They're hemorrhaging billions of dollars. It's on this AI bubble and we don't know if it's going to, you know, how it's going to look in like five or 10 years. Um, right now people are propping it up. The the chip industry is is helping um, you know, prop it up with their big buy because the AI people need servers and so they sell them the chips and then, you know, people use the the the chips and everything. So, it's a big circular basically a circular firing shot with these guys. Um and and education's also helping prop up these guys because we pay for the service that is is <57>
kind of terrible. Um and then some final thoughts. Um we don't have to use AI for writing. Um we've been writing fine for you know basically you know thousands of years. Um and we don't necessarily need this new technology. um it it might work for a few tasks and I think that we know when all the hype goes down there will actually be some uses for AI. Um sorting through large data seems to be one that seems to be an actual benefit. Uh but it's really terrible at educating students the way writing does. Uh people learning AI struggle on the job market and some AI companies are actually forbidding <58>
their candidates from using it for résumés. Um there's an article here by Anthropic and Anthropic found that people were using AI to write resumeumés and then Anthropic was hiring them. Then they figured out that they didn't know anything, you know, they they didn't know anything about the, you know, actual job they were supposedly experts in. So they actually banned AI from from job applications. an a an anthropics and AI company. Um the the Stanford uh AI lab stopped using stopped letting students use AI um and they're having all their tests done in in person because they found out that their <59>
students were becoming terrible terrible coders and terrible at finding the problems in code. So um you know even even places that are using AI are finding out that this may be a problem. Um but AI is not inevitable. In a lot of ways, we're propping up AI companies that's on that bubble. Um, even Altman says that AI market is on a bubble. Um, we need to prepare our students to think. AI teaches them not to. So, how does that help them? Our college or society. I don't know. I don't think it does. Um, so consider not allowing AI for any writing task at your college or university. um you know they <60>
they can they can work through it themselves you know give them the agency give them the ability to actually you know write and consider and think you know and really become you know professionalized in your discipline whatever that is you know um but AI takes that away from them and I think that's something that we need to really consider thanks okay Well, uh, we have some time here if, uh, anyone in the audience wants to have any kind of Q&amp;A. &gt;&gt; It looks like Emily has her I was just going to say Emily has her hand raised. I can ask you to unmute there. See? &gt;&gt; Okay. Did that <61>
work? &gt;&gt; It looks like it. &gt;&gt; I've never had that before where I wasn't allowed to unmute myself. So, um, I just I don't have a question. I thought you gave us so much good information. Um, but you began the presentation with this question of why are we doing this? And I thought you were going to talk about why are we teaching writing and maybe &gt;&gt; Oh, yeah. Yeah. &gt;&gt; Okay. But then I realized, oh, really this is a broader question, right? Why are we doing this? And I just kind of wanted to reiterate that and remind myself and everybody else. And I I really hope that we take <62>
that question with us with all the decisions that we're making in our different fields and roles at TMCC and other places in terms of what is the purpose of pushing AI if that's what we're doing. Why is that something that we want students to do? How is it benefiting them? So thinking about our role in you know professionally and and kind of the the role that we're playing for students I think is really important um given all of those things that you you know are talking about. I just I just wanted to kind of reiterate that starting question because I thought it was a really good one that we should <63>
be revisiting with all of the decisions that we make. &gt;&gt; Yeah. Um no I I totally agree Emily. Um, you know, and I I see Cheryl in the comments says like, you know, um, by restricting AI uh, writing but completely banning it doesn't prepare our students for the world of graduating into. Um, that's fine. Um, but what what is AI good for? You know, and that's that's the question, you know, if it seems to restrict their thinking and it creates problems in the workplace where even AI companies are restricting some of the usage of it, then it's creating problems. And I'm not saying resisting it <64>
across all disciplines, although I think there's probably something to that. Um that, you know, um maybe certain disciplines that find a value in it can teach people how to use it. Um but writing seems to, you know, be against that. Writing has particular rhetorical choices that students need to make, you know, and and and yeah, part of the problem I see, you know, uh Peter mentioning that how do we stop that runaway train? Um that's hugely problematic because it's being shoved down our throats in every single form. Um you know it's being integrated into everything you know um and and that's that's <65>
a big problem. Um you know I I've started using um I've I've stopped using a lot of like Microsoft products because it's embedded in everything and I found like some you know sources that are uh you know AI free online. They're like open sourced. Um, you can you can use those. Um, some search engines are better at not using AI. Duck.go is is not really using it that much. Um, and you know, I I use minus AI in a lot of searches because I don't want the AI slop in there. Um, it creates all kinds of things that are just incorrect. Um, you know, now I I saw on I think it was on Amazon the other day, <66>
uh, just streaming a TV show and it said like, "Do you want a you know, an AI summary of this?" and I'm like, "No, I just want to watch it, you know." Um, so there's there's all kinds of issues because it's being shoved into everything. But once again, it's sort of like that, you know, throw spaghetti at a wall and see what sticks. Um, it doesn't really help out certain things. In fact, a lot of the the um like the BBC study today says that when they're summarizing things, you know, it actually creates lots of errors. And so students, if they use it, they're going to be putting out errors or understanding <67>
things incorrectly because we're using it. And how does that help anybody in college? I don't want doctors who are like misunderstanding biology because they had, you know, an AI summary of an article, you know. So, it's um yeah, it's a huge problem and it's not just, you know, I can sit here and rail against it, but it's a it's a societal problem, you know. Um and I think that, you know, eventually we will find uses of AI that are actually beneficial. um you know and um but a lot of stuff we just don't need it you know we do fine with without it um and so they're they're saying we need to use <68>
it for a problem we don't have you know so I mean it it creates for me anyway it creates a lot of problems and then you know you have student engagement which has always been an issue um even getting less because you'll have students who you know I've had students who turn in papers that make no absolute no sense if you actually read it as a human, you know, it just does not make any sense. Um, no human would make the errors that the computer makes when it when it generates stuff. Um, um, let's see. Um, I'm looking here at some of the questions. Um some some apps do um and I know that like uh um <69>
a lot of uh like uh journals like if you're um if you're uh putting in an article to an academic journal uh they a lot of them now scan for AI usage. Um there was that huge problem at UNR with that um uh engineering professor who was uh who written a lot but it was all fake AI generated articles and they fired him. I don't know if you guys saw that. It was pretty hush hush but they actually canned someone for faking academic articles. Um but I've had to when I've published things I've had to you know sign a little thing saying I did not use AI and they scan it make sure it's not. Um, and so I know <70>
a lot of literary magazines do that. Um, we've gotten to the point even at the TMCC literary magazine, if we accept an article, I run it to make sure it's not AI. Um, because we've had AI stories come through and, you know, we've caught them because AI just dialogue is awful. Um, and so, you know, we've had to scan and and actually, you know, blackball people from our from our journal. Um, because they're they're trying to pass it off as something that they didn't actually create. So um but yeah so you know some of the references and stuff uh you know the journals they are doing that more and more. <71>
I wish more would do it because you're finding more and more leakage into that and I think probably the legal profession will go to something like that soon because there are so many problems with lawyers writing legal briefs and things. They're just making up case law. you know, judges are looking at, you know, these these um uh petitions and other things and they're finding all this madeup stuff. And if you're a lawyer, you know, I mean, part of your part of your uh job is to argue the truth, you know. So, um people are getting um censured and fined um and and you know, lawyers are, but you know, <72>
I don't know if that's we should tell them not to use it as part of their professionalization because they're getting in trouble from using it. I mean, you know, I don't know. &gt;&gt; Awesome. Well, I am happy to take the opportunity now to thank everyone for joining us. Thanks a lot everybody. <73>
