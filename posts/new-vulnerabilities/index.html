<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>New Vulnerabilities - AI, Writing, and Work</title>
  <link rel="stylesheet" href="../../style.css">
</head>
<body>
  <header>
    <h1>AI, Writing, and Work</h1>
    <nav>
      <a href="../../index.html">Posts</a>
      <a href="../../about.html">About</a>
    </nav>
  </header>

  <main>
    <article>
      <h2>New Vulnerabilities</h2>
      <p class="meta">February 9, 2026 Â· Follow-up to: <a href="../the-canary-in-the-codebase/">The Canary in the Codebase</a></p>

      <p>In my last post, I mapped how <a href="https://qubitn.github.io/the-vibe-schism.html">Jonas's finding</a> that 45% of AI-generated code contains security vulnerabilities connects to similar patterns in sports, music, medicine, and writing. The implication seemed clear: these vulnerabilities are dangerous, and we need to be vigilant about them.</p>

      <p>I want to push on that now. Not to retract it, but to complicate it with an analogy that I think gets closer to how I actually feel about where we are.</p>

      <h3>The Vulnerability of Meeting Someone</h3>

      <p>Think about what happens when you start a new relationship.</p>

      <p>A week ago, this person didn't exist in your life. You had a certain set of things that could hurt you, a certain set of worries, a certain emotional surface area. Then you meet someone. And almost immediately, the number of things that can cause you pain increases. There are new anxieties. Did they mean what they said? Why haven't they texted back? There are new logistical burdens&mdash;new places you have to be, new schedules to coordinate, new obligations. There are new ways your day can be ruined that literally did not exist seven days ago.</p>

      <p>In the language of software, you've introduced new security vulnerabilities into a previously stable system.</p>

      <p>Now think about what happens when a couple has their first child.</p>

      <p>The number of vulnerabilities doesn't just increase. It explodes. There are fears you have never experienced before&mdash;fears so deep they don't even have clean names. There is sleep deprivation that alters your cognition. There is financial pressure, relationship strain, identity disruption. Every single day contains problems that didn't exist a month ago. The entire system is, in security terms, riddled with new attack surfaces.</p>

      <p>And none of this is an argument against having the child.</p>

      <h3>The Mistake of Pre-Clearing</h3>

      <p>There's a certain kind of person&mdash;and I say this with sympathy because I recognize it in myself&mdash;who believes you should have everything planned before you take the leap. You should be financially ready. Emotionally ready. You should have read the books, taken the classes, prepared the nursery, worked through your own childhood issues in therapy. You should have, in effect, patched all the security vulnerabilities before they appear.</p>

      <p>But that's not how it works. You can't patch a vulnerability that doesn't exist yet. The specific fears that come with being a parent are not available to you before you are a parent. The particular ways your relationship will be stressed are not predictable from the outside. The emotional reality of 3 a.m. with a screaming infant cannot be pre-experienced and pre-solved. It can only be entered.</p>

      <p>The vulnerabilities are not a sign that something went wrong. They are a sign that something new is happening. They're the <em>cost</em> of the new thing, and the new thing is worth the cost, and you were never going to be able to pay that cost in advance.</p>

      <h3>Safety as the Mistake</h3>

      <p>Here's where the analogy turns into my actual argument about AI.</p>

      <p>The dominant posture toward AI right now&mdash;in education, in many workplaces, in public discourse&mdash;is caution. Wait until we understand it. Wait until we have frameworks. Wait until the risks are mapped. Don't move until you can move safely.</p>

      <p>I think that posture is more dangerous than the thing it's trying to protect against.</p>

      <p>Not because the risks aren't real. Jonas is right that AI-generated code has security holes. The skill atrophy findings are real. The productivity paradox is real. <a href="https://kevionmilton.github.io/the-cold-doctor-ai-healthcare.html">Kevion is right</a> that the dashboard can say "healthy" while the athlete's brain is screaming. <a href="https://bellacalmetjanssen-cell.github.io/isabella-calmet-.github.io/architectural-agency-ai.html">Isabella is right</a> that "mastery atrophy" is a genuine threat across domains.</p>

      <p>But the existence of new vulnerabilities is not evidence that the change was a mistake. It's evidence that the change is real. And the vulnerabilities are only legible from the inside. You can only see them once you're in the new world. Which means the only way to address them is to enter the new world and start addressing them.</p>

      <p>Waiting to feel ready is the trap. Readiness is not a state you achieve before the transition. It's something you develop during the transition, in response to problems you could not have anticipated.</p>

      <h3>What You Learn by Moving</h3>

      <p>Parents don't become competent parents by reading about parenting. They become competent parents by failing, in real time, with a real child, and adjusting. The failing is not a deviation from the process. It <em>is</em> the process. The 3 a.m. crisis you couldn't have predicted is exactly what teaches you who you are under pressure. The vulnerability was the lesson.</p>

      <p>I think the same is true here. The students in this network who are using AI seriously&mdash;who are generating text with it, arguing with its output, discovering what it gets wrong, figuring out what it can't do, noticing where their own thinking goes slack when they lean on it&mdash;those students are learning something that no amount of cautious distance can teach. They're developing a feel for the technology by being inside its failure modes.</p>

      <p>Jonas didn't learn about the verification gap by avoiding vibe coding. He learned about it by studying what happens when people do it. <a href="https://zayamaro.github.io/the-simulation-trap.html">Zay</a> didn't learn about the simulation trap by staying away from sports analytics. He learned about it by pushing into the question of what happens when the data is <em>too</em> good. These insights came from engagement, not from caution.</p>

      <h3>The Fear That Prevents the Learning</h3>

      <p>The person who refuses to start a relationship until they're certain they won't get hurt will never start a relationship. The certainty they're waiting for is produced by the experience they're avoiding.</p>

      <p>The institution that refuses to let students use AI until they've figured out how to prevent misuse will never figure out how to prevent misuse. The understanding they're waiting for is produced by the engagement they're forbidding.</p>

      <p>The professional who refuses to integrate AI into their workflow until they're sure it won't erode their skills will not develop the judgment to know where the erosion happens. That judgment comes from using the tool, watching yourself change, and adjusting. It's not available from the outside.</p>

      <p>Fear and caution feel responsible. They feel like the mature, careful response. But when they prevent engagement, they prevent exactly the learning that would make engagement safe. Caution becomes the thing that ensures you're unprepared.</p>

      <h3>So What Am I Actually Saying?</h3>

      <p>I'm saying the vulnerabilities are real, and they're also fine. Not fine in the sense that they don't matter. Fine in the sense that they're the expected and necessary cost of entering a new situation that's worth entering.</p>

      <p>Every meaningful change in human life introduces problems that didn't exist before. New relationships. New children. New technologies. New tools. The problems are not evidence against the change. They are the texture of the change. And the only way to develop competence in the new situation is to be in the new situation, encountering its problems, and working through them.</p>

      <p>The 45% security vulnerability rate in AI-generated code is not an argument to stop using AI for code. It's an argument to get very good, very fast, at spotting security vulnerabilities in AI-generated code&mdash;a skill that can only be developed by people who are actually working with AI-generated code.</p>

      <p>The skill atrophy problem is not an argument to keep AI out of education. It's a phenomenon that can only be understood and addressed by people who are inside the experience of using AI for intellectual work&mdash;noticing where their thinking gets lazy, noticing where the tool does something they couldn't, noticing where the output looks right but feels wrong.</p>

      <p>Move forward. Pay attention. Fix what breaks. That's not recklessness. That's how every significant human transition has ever worked.</p>

    </article>
  </main>

  <footer>
    <p>A blog about AI in writing and intellectual work.</p>
  </footer>
</body>
</html>
